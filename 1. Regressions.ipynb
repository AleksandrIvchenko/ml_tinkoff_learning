{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрационные примеры для задач линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RANSACRegressor\n",
    "from ipywidgets import interact\n",
    "from ipywidgets.widgets import FloatSlider, IntSlider\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f974386f5bc40b0bce8e4d2c76f7e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='a', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(a=FloatSlider(min=-2, max=2, step=0.1, value=1),\n",
    "          b=FloatSlider(min=-1, max=1, step=0.1, value=0),\n",
    "          e=FloatSlider(min=0, max=2, step=0.01, value=0.1),\n",
    "          n=IntSlider(min=2, max=200, step=2, value=50))\n",
    "def linear_regression_1d(a, b, e=0.5, n=100):\n",
    "    \"\"\"\n",
    "    Оцениваем по формуле параметры a и b одномерной линейной регрессии: y = a*x + b\n",
    "    e : уровень шума\n",
    "    n : количество точек\n",
    "    \"\"\"\n",
    "    xmin = 0\n",
    "    xmax = 5\n",
    "    np.random.seed(42)\n",
    "    x = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    y = a*x + b + e*np.random.randn(n)\n",
    "    a_hat = ((x - x.mean())*(y - y.mean())).sum()/((x - x.mean())**2).sum()\n",
    "    # a_hat = (x*(y - y.mean())).sum()/(x*(x - x.mean())).sum()    \n",
    "    b_hat = y.mean() - a_hat*x.mean()\n",
    "    y_pred = a_hat*x + b_hat\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a + b, x.max()*a + b], label='true', c='b')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a_hat + b_hat, x.max()*a_hat + b_hat], label='pred', c='r')\n",
    "    plt.ylim(-12, 12)\n",
    "    plt.legend()\n",
    "    plt.title(f'a\\u0302={a_hat:.5} b\\u0302={b_hat:.5} r2={r2:.5} mse={mse:.5} mae={mae:.5}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5471f023e1804f80a7ab0d960584b21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='a', max=2.0, min=-2.0), FloatSlider(value=1.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "@interact(a=FloatSlider(min=-2, max=2, step=0.1, value=1),\n",
    "          b=FloatSlider(min=-2, max=2, step=0.1, value=1),\n",
    "          c=FloatSlider(min=-1, max=1, step=0.1, value=0),\n",
    "          e=FloatSlider(min=0, max=2, step=0.01, value=0.1),\n",
    "          n=IntSlider(min=3, max=200, step=3, value=50))\n",
    "def linear_regression_2d(a, b, c, e=0.5, n=100):\n",
    "    \"\"\"\n",
    "    Оцениваем параметры a, b и с двумерной линейной регрессии: y = a*x1 + b*x2 + c\n",
    "    e : уровень шума\n",
    "    n : количество точек\n",
    "    \"\"\"\n",
    "    xmin = 0\n",
    "    xmax = 5\n",
    "    np.random.seed(42)\n",
    "    x0 = np.ones(n)\n",
    "    x1 = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    x2 = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    y = a*x1 + b*x2 + c + e*np.random.randn(n)\n",
    "    xt = np.stack((x0, x1, x2))\n",
    "    x = xt.transpose()\n",
    "    w_hat = np.linalg.inv(xt@x)@xt@y\n",
    "    c_hat, a_hat, b_hat = w_hat.tolist()\n",
    "    print(w_hat)\n",
    "    y_pred = a_hat*x1 + b_hat*x2 + c_hat\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x1, x2, y)\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_zlabel('y')\n",
    "    plt.ylim(-12, 12)\n",
    "    plt.title(f'a\\u0302={a_hat:.4} b\\u0302={b_hat:.4} c\\u0302={c_hat:.4} ' + \n",
    "              f'r2={r2:.4} mse={mse:.4} mae={mae:.4}')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d0725969424e7a9deb2d58918dd144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='a', max=2.0, min=-2.0), FloatSlider(value=1.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(a=FloatSlider(min=-2, max=2, step=0.1, value=1),\n",
    "          b=FloatSlider(min=-2, max=2, step=0.1, value=1),\n",
    "          c=FloatSlider(min=-1, max=1, step=0.1, value=0),\n",
    "          k=FloatSlider(min=0, max=0.5, step=0.01, value=0.5),\n",
    "          e=FloatSlider(min=0, max=2, step=0.01, value=0.1),\n",
    "          n=IntSlider(min=3, max=200, step=3, value=50))\n",
    "def linear_regression_2d_multicollinearity(a, b, c, k, e=0.5, n=100):\n",
    "    \"\"\"\n",
    "    Оцениваем параметры a, b и с двумерной линейной регрессии: y = a*x1 + b*x2 + c\n",
    "    Моделирование полной или частичной мультиколлинеарности (k=0 для полной).\n",
    "    Используем различные способы оценки.\n",
    "    e : уровень шума\n",
    "    n : количество точек\n",
    "    \"\"\"\n",
    "    xmin = 0\n",
    "    xmax = 5\n",
    "    np.random.seed(42)\n",
    "    x0 = np.ones(n)\n",
    "    x1 = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    x2 = x1 + k*np.random.randn(n)\n",
    "    y = a*x1 + b*x2 + c + e*np.random.randn(n)\n",
    "    \n",
    "    # вычислим коэффициенты регрессии по формуле (XT@X)^-1@XT@Y\n",
    "    xt = np.stack((x0, x1, x2))\n",
    "    x = xt.transpose()\n",
    "    w_hat = np.zeros(3)\n",
    "    try:\n",
    "        w_hat = np.linalg.inv(xt@x)@xt@y\n",
    "    except BaseException as ex:\n",
    "        print(f'Raw formula error: {ex}')\n",
    "    c_hat, a_hat, b_hat = w_hat.tolist()\n",
    "    print(f'w_hat={w_hat} Raw formula')\n",
    "    \n",
    "    # вычислим псевдообратную матрицу с помощью SVD:\n",
    "    u, s, vh = np.linalg.svd(x)\n",
    "    s_inv = np.identity(3)*(s**-1)\n",
    "    x_pi = vh.transpose()@s_inv@u.transpose()[:3,:]\n",
    "    \n",
    "    # вычислим коэффициенты регрессии с помощью псевдообратной матрицы:\n",
    "    w_hat_pi = x_pi@y\n",
    "    print(f'w_hat={w_hat_pi} Pseudoinverse matrix')\n",
    "    \n",
    "    # вычислим коэффиценты регрессии с помощью LinearRegression\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(x, y)\n",
    "    w_hat_lr = np.hstack((np.array(linear_regression.intercept_), linear_regression.coef_[1:]))\n",
    "    print(f'w_hat={w_hat_lr} LinearRegression')\n",
    "    \n",
    "    # вычислим коэффиценты регрессии с помощью Ridge\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(x, y)\n",
    "    w_hat_ridge = np.hstack((np.array(ridge.intercept_), ridge.coef_[1:]))\n",
    "    print(f'w_hat={w_hat_ridge} Ridge')\n",
    "    \n",
    "    # вычислим коэффиценты регрессии с помощью LASSO\n",
    "    lasso = Lasso()\n",
    "    lasso.fit(x, y)\n",
    "    w_hat_lasso = np.hstack((np.array(lasso.intercept_), lasso.coef_[1:]))\n",
    "    print(f'w_hat={w_hat_lasso} LASSO')\n",
    "    \n",
    "    # выведем сингулярные числа ():\n",
    "    print(f'\\u03bb**0.5={s}')\n",
    "    # выведем собственные значения матрицы XT@X:\n",
    "    print(f'\\u03bb(XT@X)={s**2}  {round((s**2).max()/(s**2).min(),3)}')\n",
    "    \n",
    "    y_pred = a_hat*x1 + b_hat*x2 + c_hat\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    plt.scatter(x1, x2)\n",
    "    plt.xlabel('x1')\n",
    "    plt.xlim(-1, 6)\n",
    "    plt.ylabel('x2')\n",
    "    plt.ylim(-1, 6)\n",
    "    plt.title(f'a\\u0302={a_hat:.5} b\\u0302={b_hat:.5} c\\u0302={c_hat:.4} ' + \n",
    "              f'r2={r2:.5} mse={mse:.5} mae={mae:.5}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dbe8c556b84fe8873503bd98bfa937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-2.0, description='a', max=2.0, min=-2.0), FloatSlider(value=-1.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(a=FloatSlider(min=-2, max=2, step=0.1, value=-2),\n",
    "          b=FloatSlider(min=-1, max=1, step=0.1, value=-1),\n",
    "          e=FloatSlider(min=0, max=2, step=0.01, value=0.1),\n",
    "          n=IntSlider(min=2, max=200, step=2, value=30),\n",
    "          ox=FloatSlider(min=0, max=5, step=0.1, value=2.5),\n",
    "          oy=FloatSlider(min=-2, max=2, step=0.1, value=0.5),\n",
    "          on=IntSlider(min=0, max=20, step=1, value=5))\n",
    "def linear_regression_1d_ransac(a, b, e=0.5, n=100, ox=0.5, oy=0.5, on=5):\n",
    "    \"\"\"\n",
    "    Оцениваем с помощью RANSAC параметры a и b одномерной линейной регрессии: y = a*x + b\n",
    "    e : уровень шума\n",
    "    n : количество точек\n",
    "    ox, oy : координаты центра выборосов\n",
    "    on : количество точек с выбросом\n",
    "    \"\"\"\n",
    "    xmin = 0\n",
    "    xmax = 5\n",
    "    np.random.seed(42)\n",
    "    x = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    y = a*x + b + e*np.random.randn(n)\n",
    "    xo = np.random.randn(on) + ox\n",
    "    yo = np.random.randn(on) + oy\n",
    "    X = np.hstack((x, xo)).reshape((n + on, 1))\n",
    "    Y = np.hstack((y, yo))\n",
    "    ransac_regressor = RANSACRegressor()\n",
    "    ransac_regressor.fit(X,Y)\n",
    "    a_hat = ransac_regressor.estimator_.coef_[0]\n",
    "    b_hat = ransac_regressor.estimator_.intercept_\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(X,Y)\n",
    "    lr_a_hat = linear_regression.coef_[0]\n",
    "    lr_b_hat = linear_regression.intercept_\n",
    "    \n",
    "    y_pred = a_hat*x + b_hat\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    plt.scatter(x, y, c='b', marker='o')\n",
    "    plt.scatter(xo, yo, c='r', marker='^')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a + b, x.max()*a + b], label='true', c='b')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a_hat + b_hat, x.max()*a_hat + b_hat], label='RANSAC', c='r')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*lr_a_hat + lr_b_hat, x.max()*lr_a_hat + lr_b_hat], label='Linear regression', c='g')\n",
    "    plt.ylim(-12, 12)\n",
    "    plt.legend()\n",
    "    plt.title(f'a\\u0302={a_hat:.5} b\\u0302={b_hat:.5} r2={r2:.5} mse={mse:.5} mae={mae:.5}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import huber\n",
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651ae47e52f34b0fb9aed12f10a6aa84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-2.0, description='a', max=2.0, min=-2.0), FloatSlider(value=-1.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(a=FloatSlider(min=-2, max=2, step=0.1, value=-2),\n",
    "          b=FloatSlider(min=-1, max=1, step=0.1, value=-1),\n",
    "          e=FloatSlider(min=0, max=2, step=0.01, value=0.1),\n",
    "          n=IntSlider(min=2, max=200, step=2, value=30),\n",
    "          ox=FloatSlider(min=0, max=5, step=0.1, value=2.5),\n",
    "          oy=FloatSlider(min=-2, max=2, step=0.1, value=0.5),\n",
    "          on=IntSlider(min=0, max=20, step=1, value=5))\n",
    "def linear_regression_1d_ransac(a, b, e=0.5, n=100, ox=0.5, oy=0.5, on=5):\n",
    "    \"\"\"\n",
    "    Оцениваем с помощью RANSAC параметры a и b одномерной линейной регрессии: y = a*x + b\n",
    "    e : уровень шума\n",
    "    n : количество точек\n",
    "    ox, oy : координаты центра выборосов\n",
    "    on : количество точек с выбросом\n",
    "    \"\"\"\n",
    "    xmin = 0\n",
    "    xmax = 5\n",
    "    np.random.seed(42)\n",
    "    x = np.random.rand(n)*(xmax - xmin) + xmin\n",
    "    y = a*x + b + e*np.random.randn(n)\n",
    "    xo = np.random.randn(on) + ox\n",
    "    yo = np.random.randn(on) + oy\n",
    "    X = np.hstack((x, xo)).reshape((n + on, 1))\n",
    "    Y = np.hstack((y, yo))\n",
    "    ransac_regressor = RANSACRegressor()\n",
    "    ransac_regressor.fit(X,Y)\n",
    "    a_hat = ransac_regressor.estimator_.coef_[0]\n",
    "    b_hat = ransac_regressor.estimator_.intercept_\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(X,Y)\n",
    "    lr_a_hat = linear_regression.coef_[0]\n",
    "    lr_b_hat = linear_regression.intercept_\n",
    "    \n",
    "    #\n",
    "    huber = HuberRegressor().fit(X,Y)\n",
    "    lr_a_hu = huber.coef_[0]\n",
    "    lr_b_hu = huber.intercept_\n",
    "    #\n",
    "    \n",
    "    y_pred = a_hat*x + b_hat\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    #hu = huber (y, y_pred)\n",
    "    \n",
    "    #print (hu)\n",
    "    \n",
    "    plt.scatter(x, y, c='b', marker='o')\n",
    "    plt.scatter(xo, yo, c='r', marker='^')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a + b, x.max()*a + b], label='true', c='b')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*a_hat + b_hat, x.max()*a_hat + b_hat], label='RANSAC', c='r')\n",
    "    plt.plot([x.min(), x.max()], [x.min()*lr_a_hat + lr_b_hat, x.max()*lr_a_hat + lr_b_hat], label='Linear regression', c='g')\n",
    "    \n",
    "    plt.plot([x.min(), x.max()], [x.min()*lr_a_hu + lr_b_hu, x.max()*lr_a_hu + lr_b_hu], label='Huber regression', c='c')\n",
    "    \n",
    "    plt.ylim(-12, 12)\n",
    "    plt.legend()\n",
    "    #plt.title(f'a\\u0302={a_hat:.5} b\\u0302={b_hat:.5} r2={r2:.5} mse={mse:.5} mae={mae:.5} hu={hu:.5}' )\n",
    "    plt.title(f'a\\u0302={a_hat:.5} b\\u0302={b_hat:.5} r2={r2:.5} mse={mse:.5} mae={mae:.5}' )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
